# ============================================================================
# LITELLM CONFIGURATION
# ============================================================================
# Unified gateway for multiple LLM providers
# Docs: https://docs.litellm.ai/docs/proxy/configs
# ============================================================================

model_list:
  # OpenAI Models
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY

  # Anthropic Models
  - model_name: claude-3-5-sonnet-20241022
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-3-5-haiku-20241022
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY

# Router settings
router_settings:
  routing_strategy: usage-based-routing  # or latency-based-routing, simple-shuffle
  num_retries: 3
  timeout: 600  # 10 minutes for long-running requests
  fallbacks: []  # Add fallback models if needed

# General settings
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL

  # Cost tracking
  track_cost_per_deployment: true

  # Caching (requires Redis)
  cache: true
  cache_type: redis

  # Rate limiting
  max_parallel_requests: 1000
  global_max_parallel_requests: 1000

# Logging
litellm_settings:
  # Log LLM API calls to Langfuse
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]

  # Callbacks configuration for Langfuse
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST
