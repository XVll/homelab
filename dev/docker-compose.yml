# ============================================================================
# DEV VM (10.10.10.114) - Development Stack
# ============================================================================
# Gitea: Git hosting + Container Registry + CI/CD (Gitea Actions)
# act_runner: Executes Gitea Actions workflows
# Dokploy: Deployment platform with built-in Traefik
# ============================================================================

services:
  # ============================================================================
  # PORTAINER AGENT - Container Management
  # ============================================================================
  # Connects to Portainer on observability VM (10.10.10.112:9443)

  portainer-agent:
    image: portainer/agent:latest
    container_name: portainer-agent
    restart: always
    ports:
      - "9001:9001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
      - /:/host
    networks:
      - dev_net
    # No health check - minimal container without shell/utilities
    # Portainer server monitors agent connectivity
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # ALLOY - Metrics & Logs Collector (sends to observability VM)
  # ============================================================================

  alloy:
    image: grafana/alloy:latest
    container_name: alloy
    restart: unless-stopped
    privileged: true  # Required for system metrics collection
    command:
      - run
      - /etc/alloy/config.alloy
      - --server.http.listen-addr=0.0.0.0:12345
      - --storage.path=/var/lib/alloy/data
    ports:
      - "10.10.10.114:12345:12345"  # Alloy UI
    volumes:
      - ./alloy/config/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker metrics + logs
      - /:/host/root:ro  # System metrics (CPU, disk, etc.)
      - /sys:/host/sys:ro  # System metrics
      - /proc:/host/proc:ro  # System metrics
      - /var/lib/docker:/var/lib/docker:ro  # Docker container info for cAdvisor
      - /dev/disk:/dev/disk:ro  # Disk info for cAdvisor
      - /sys/fs/cgroup:/sys/fs/cgroup:ro  # cgroups for container metrics
      - ./alloy/data:/var/lib/alloy/data  # Alloy state
    networks:
      - dev_net
    environment:
      - HOSTNAME=dev
    healthcheck:
      test: ["CMD-SHELL", "alloy tools pprof health http://localhost:12345 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # NETDATA - Real-Time System & Container Monitoring
  # ============================================================================
  # Real-time performance monitoring with 1-second granularity
  # Streams to parent on observability VM (10.10.10.112)
  # Web UI: http://10.10.10.114:19999
  # Documentation: https://learn.netdata.cloud

  netdata:
    image: netdata/netdata:latest
    container_name: netdata
    hostname: dev
    restart: unless-stopped
    pid: host
    cap_add:
      - SYS_PTRACE
      - SYS_ADMIN
    security_opt:
      - apparmor:unconfined
    ports:
      - "10.10.10.114:19999:19999"
    volumes:
      - ./netdata/config:/etc/netdata
      - ./netdata/lib:/var/lib/netdata
      - ./netdata/cache:/var/cache/netdata
      - /:/host/root:ro,rslave
      - /etc/passwd:/host/etc/passwd:ro
      - /etc/group:/host/etc/group:ro
      - /etc/localtime:/etc/localtime:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /etc/os-release:/host/etc/os-release:ro
      - /var/log:/host/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - dev_net
    environment:
      - NETDATA_CLAIM_TOKEN=${NETDATA_CLAIM_TOKEN}
      - NETDATA_CLAIM_ROOMS=${NETDATA_CLAIM_ROOMS}
      - NETDATA_CLAIM_URL=https://app.netdata.cloud
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # GITEA - Self-hosted Git with Actions & Container Registry
  # ==========================================================================
  gitea:
    image: gitea/gitea:1.24
    container_name: gitea
    restart: unless-stopped
    environment:
      # User/Group
      - USER_UID=1000
      - USER_GID=1000

      # Database (PostgreSQL on db host)
      # Only pre-configure database connection - all other settings via web installer
      - GITEA__database__DB_TYPE=postgres
      - GITEA__database__HOST=10.10.10.111:5432
      - GITEA__database__NAME=gitea
      - GITEA__database__USER=gitea
      - GITEA__database__PASSWD=${GITEA_DB_PASSWORD}

    ports:
      - "10.10.10.114:3001:3000"  # HTTP
      - "10.10.10.114:222:22"      # SSH

    volumes:
      - ./gitea/data:/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro

    networks:
      - dev_net

    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ==========================================================================
  # ACT RUNNER - Executes Gitea Actions workflows
  # ==========================================================================
  act-runner:
    image: gitea/act_runner:latest
    container_name: act-runner
    restart: unless-stopped

    volumes:
      - ./act-runner/data:/data
      - /var/run/docker.sock:/var/run/docker.sock:ro

    environment:
      - GITEA_INSTANCE_URL=http://gitea:3000
      - GITEA_RUNNER_REGISTRATION_TOKEN=${GITEA_RUNNER_TOKEN}
      - GITEA_RUNNER_NAME=homelab-runner
      - GITEA_RUNNER_LABELS=ubuntu-latest:docker://node:20-bookworm,ubuntu-22.04:docker://node:20-bookworm

    networks:
      - dev_net

    depends_on:
      gitea:
        condition: service_healthy

    healthcheck:
      test: ["CMD-SHELL", "test -f /data/.runner || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # ==========================================================================
  # DOKPLOY - Deployment Platform (Commented out - deploy separately)
  # ==========================================================================
  # Dokploy installation uses its own installer script
  # Run: curl -sSL https://dokploy.com/install.sh | sh
  # This will set up Dokploy with its own Traefik instance

  # ==========================================================================
  # SONARQUBE - Code Quality & Security Analysis
  # ==========================================================================
  # Static code analysis, security scanning, tech debt tracking
  # Uses external PostgreSQL on db VM (10.10.10.111)
  # Access: https://sonar.onurx.com
  # Default credentials: admin/admin (change on first login)

  sonarqube:
    image: sonarqube:community
    container_name: sonarqube
    restart: unless-stopped
    ports:
      - "9000:9000"
    environment:
      # Database
      - SONAR_JDBC_URL=jdbc:postgresql://10.10.10.111:5432/sonarqube
      - SONAR_JDBC_USERNAME=${SONARQUBE_DB_USER}
      - SONAR_JDBC_PASSWORD=${SONARQUBE_DB_PASSWORD}

      # Web settings
      - SONAR_WEB_CONTEXT=/
      - SONAR_WEB_PORT=9000
    volumes:
      - ./sonarqube/data:/opt/sonarqube/data
      - ./sonarqube/extensions:/opt/sonarqube/extensions
      - ./sonarqube/logs:/opt/sonarqube/logs
    networks:
      - dev_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/api/system/status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # MEILISEARCH - Fast, Typo-Tolerant Search Engine
  # ==========================================================================
  # Lightweight search engine for applications
  # Self-contained (no external database needed)
  # Access: https://search.onurx.com
  # Use cases: Product search, documentation, autocomplete, content discovery

  meilisearch:
    image: getmeili/meilisearch:v1.12
    container_name: meilisearch
    restart: unless-stopped
    ports:
      - "7700:7700"
    environment:
      - MEILI_MASTER_KEY=${MEILISEARCH_MASTER_KEY}
      - MEILI_ENV=production
      - MEILI_HTTP_ADDR=0.0.0.0:7700
    volumes:
      - ./meilisearch/data:/meili_data
    networks:
      - dev_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7700/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # INNGEST - AI/Workflow Orchestration Platform
  # ==========================================================================
  # Self-hosted workflow engine for AI agents, durable functions, event-driven apps
  # Uses external PostgreSQL (10.10.10.111) and Redis (10.10.10.111)
  # Access: https://inngest.onurx.com
  # Use cases: AI agents, LLM workflows, background jobs, event-driven architecture

  inngest:
    image: inngest/inngest:latest
    container_name: inngest
    restart: unless-stopped
    command: inngest start
    ports:
      - "8288:8288"  # Main API
      - "8289:8289"  # Connect Gateway
    environment:
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_POSTGRES_URI=postgresql://${INNGEST_DB_USER}:${INNGEST_DB_PASSWORD}@10.10.10.111:5432/inngest
      - INNGEST_REDIS_URI=redis://:${REDIS_PASSWORD}@10.10.10.111:6379/1
    networks:
      - dev_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8288/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # INFISICAL - Secrets Management Platform
  # ==========================================================================
  # Open-source secrets management for developers and infrastructure
  # Uses external PostgreSQL and Redis on db VM (10.10.10.111)
  # Access: https://secrets.onurx.com
  # Documentation: https://infisical.com/docs

  infisical:
    image: infisical/infisical:latest
    container_name: infisical
    restart: unless-stopped
    ports:
      - "8082:8080"
    environment:
      # Database (PostgreSQL on db host)
      - DB_CONNECTION_URI=postgresql://${INFISICAL_DB_USER}:${INFISICAL_DB_PASSWORD}@10.10.10.111:5432/infisical

      # Redis (on db host)
      - REDIS_URL=redis://:${REDIS_PASSWORD}@10.10.10.111:6379/2

      # Site configuration
      - SITE_URL=https://secrets.onurx.com

      # Encryption keys (required for secrets encryption)
      - ENCRYPTION_KEY=${INFISICAL_ENCRYPTION_KEY}
      - AUTH_SECRET=${INFISICAL_AUTH_SECRET}

      # Telemetry (opt-out)
      - TELEMETRY_ENABLED=false
    networks:
      - dev_net
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # HOPPSCOTCH - API Development & Testing Platform
  # ==========================================================================
  # All-in-one container with frontend, backend, and admin
  # Uses external PostgreSQL on db VM (10.10.10.111)
  # Access: https://api.onurx.com

  hoppscotch:
    image: hoppscotch/hoppscotch:2025.10.0
    container_name: hoppscotch
    restart: unless-stopped
    ports:
      - "3000:80"     # Frontend (Caddy serves on port 80 internally)
      - "3100:80"     # Admin (same Caddy instance)
      - "3170:8080"   # Backend API
    environment:
      # Database
      - DATABASE_URL=postgresql://${HOPPSCOTCH_DB_USER}:${HOPPSCOTCH_DB_PASSWORD}@10.10.10.111:5432/hoppscotch?connect_timeout=300

      # Security
      - DATA_ENCRYPTION_KEY=${HOPPSCOTCH_ENCRYPTION_KEY}

      # URLs (accessed via Traefik)
      - VITE_BASE_URL=https://api.onurx.com
      - VITE_BACKEND_GQL_URL=https://api.onurx.com/backend/graphql
      - VITE_BACKEND_WS_URL=wss://api.onurx.com/backend/graphql
      - VITE_BACKEND_API_URL=https://api.onurx.com/backend/v1

      # Subpath access
      - ENABLE_SUBPATH_BASED_ACCESS=true

      # Application settings
      - VITE_ALLOWED_AUTH_PROVIDERS=EMAIL
      - REDIRECT_URL=https://api.onurx.com
      - WHITELISTED_ORIGINS=https://api.onurx.com,https://api.onurx.com/admin,https://api.onurx.com/backend
      - VITE_APP_TOS_LINK=https://api.onurx.com
      - VITE_APP_PRIVACY_POLICY_LINK=https://api.onurx.com
    networks:
      - dev_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  dev_net:
    driver: bridge
    name: dev_net
