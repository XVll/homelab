# ============================================================================
# PROMETHEUS CONFIGURATION - Modern Alloy-based Setup
# ============================================================================
# All system and Docker metrics are collected by Alloy and sent via remote_write
# Prometheus scrapes only:
# 1. Services that expose Prometheus metrics directly (Traefik, MinIO, etc.)
# 2. Alloy's own internal metrics
# 3. Observability stack components (Grafana, Loki, Prometheus itself)
# ============================================================================

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  scrape_timeout: 10s
  external_labels:
    cluster: 'homelab'
    environment: 'production'

# Alertmanager configuration (optional - add later)
# alerting:
#   alertmanagers:
#     - static_configs:
#         - targets:
#           - alertmanager:9093

# Load alerting rules
rule_files:
  - '/etc/prometheus/rules/*.yml'

# ============================================================================
# SCRAPE CONFIGURATIONS
# ============================================================================

scrape_configs:
  # --------------------------------------------------------------------------
  # Observability Stack (local services)
  # --------------------------------------------------------------------------

  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          instance: 'prometheus'
          vm: 'observability'
          service: 'observability'

  # Grafana
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']
        labels:
          instance: 'grafana'
          vm: 'observability'
          service: 'observability'

  # Loki
  - job_name: 'loki'
    static_configs:
      - targets: ['loki:3100']
        labels:
          instance: 'loki'
          vm: 'observability'
          service: 'observability'

  # Alloy - internal metrics only (system/Docker metrics come via remote_write)
  - job_name: 'alloy'
    static_configs:
      - targets: ['alloy:12345']
        labels:
          instance: 'alloy'
          vm: 'observability'
          service: 'observability'

  # --------------------------------------------------------------------------
  # Edge Services (VM: 10.10.10.110)
  # --------------------------------------------------------------------------

  # Traefik - exposes metrics directly on dedicated port
  - job_name: 'traefik'
    static_configs:
      - targets: ['10.10.10.110:8082']
        labels:
          instance: 'traefik'
          vm: 'edge'
          service: 'proxy'

  # --------------------------------------------------------------------------
  # Database Services (VM: 10.10.10.111)
  # --------------------------------------------------------------------------

  # MinIO - exposes metrics directly (requires bearer token auth - disabled for now)
  # To enable: need to configure bearer_token or bearer_token_file
  # - job_name: 'minio'
  #   metrics_path: /minio/v2/metrics/cluster
  #   scheme: http
  #   static_configs:
  #     - targets: ['10.10.10.111:9000']
  #       labels:
  #         instance: 'minio'
  #         vm: 'db'
  #         service: 'storage'

  # Note: PostgreSQL, MongoDB, Redis metrics would need separate exporters
  # For now, rely on Alloy to collect Docker container metrics
  # Can add dedicated exporters later if needed

  # --------------------------------------------------------------------------
  # Media Services (VM: 10.10.10.113) - NOT DEPLOYED YET
  # --------------------------------------------------------------------------
  # Uncomment when media services are deployed:
  #
  # - job_name: 'sonarr'
  #   static_configs:
  #     - targets: ['10.10.10.113:8989']
  #       labels:
  #         instance: 'sonarr'
  #         vm: 'media'
  #         service: 'media'
  #
  # - job_name: 'radarr'
  #   static_configs:
  #     - targets: ['10.10.10.113:7878']
  #       labels:
  #         instance: 'radarr'
  #         vm: 'media'
  #         service: 'media'
  #
  # - job_name: 'prowlarr'
  #   static_configs:
  #     - targets: ['10.10.10.113:9696']
  #       labels:
  #         instance: 'prowlarr'
  #         vm: 'media'
  #         service: 'media'

  # --------------------------------------------------------------------------
  # SNMP Devices (Synology NAS, Network Gear, etc.)
  # --------------------------------------------------------------------------

  # Synology NAS - SNMP monitoring (no agent required)
  # Uses official synology module + homelab_v2 auth from snmp.yml
  - job_name: 'synology'
    static_configs:
      - targets:
        - 10.10.10.100  # Synology NAS IP (Xpenology)
    metrics_path: /snmp
    params:
      auth: [homelab_v2]
      module: [synology]
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: snmp-exporter:9116  # SNMP exporter address
      - source_labels: [__param_target]
        target_label: hostname
        replacement: 'synology'
      - target_label: vm
        replacement: 'synology'
      - target_label: service
        replacement: 'nas'

  # --------------------------------------------------------------------------
  # Home Automation (VM: 10.10.10.116)
  # --------------------------------------------------------------------------

  # Home Assistant - native Prometheus integration
  # Config in HA: prometheus: { namespace: homeassistant, requires_auth: false }
  # No auth required - safe on internal network (10.10.10.0/24)
  - job_name: 'homeassistant'
    scrape_interval: 60s
    static_configs:
      - targets: ['10.10.10.116:8123']
        labels:
          instance: 'homeassistant'
          vm: 'ha'
          service: 'automation'
    metrics_path: /api/prometheus
    scheme: http

# ============================================================================
# NOTES FOR FUTURE EXPANSION
# ============================================================================
#
# To monitor additional VMs:
# 1. Deploy Alloy on each VM (same config, update hostname)
# 2. Alloy automatically sends metrics via remote_write to this Prometheus
# 3. Add Alloy scrape target here (optional, for Alloy's own metrics)
#
# Example for edge VM:
#   - job_name: 'alloy-edge'
#     static_configs:
#       - targets: ['10.10.10.110:12345']
#         labels:
#           instance: 'alloy'
#           vm: 'edge'
#
# For database-specific metrics, add exporters:
# - PostgreSQL Exporter: postgres_exporter
# - MongoDB Exporter: mongodb_exporter
# - Redis Exporter: redis_exporter
# ============================================================================
